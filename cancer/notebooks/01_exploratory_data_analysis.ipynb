{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf3c6b6",
   "metadata": {},
   "source": [
    "# An√°lisis Exploratorio de Datos de C√°ncer - TCIA\n",
    "\n",
    "Este notebook proporciona un an√°lisis exploratorio completo de datos de c√°ncer obtenidos de The Cancer Imaging Archive (TCIA). Incluye:\n",
    "\n",
    "- Conexi√≥n y descarga de datos desde TCIA\n",
    "- Procesamiento de im√°genes DICOM\n",
    "- An√°lisis estad√≠stico descriptivo\n",
    "- Visualizaciones interactivas\n",
    "- Preprocesamiento para modelos de ML\n",
    "\n",
    "## Configuraci√≥n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82eb00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necesarios\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Agregar src al path\n",
    "src_path = Path('../src').absolute()\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "# Imports principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Configurar estilo de visualizaciones\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(f\"An√°lisis iniciado: {datetime.now()}\")\n",
    "print(f\"Directorio de trabajo: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab5d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar m√≥dulos del proyecto\n",
    "try:\n",
    "    from utils.tcia_client import TCIAClient\n",
    "    from utils.dicom_processor import DICOMProcessor\n",
    "    from utils.gemini_analyzer import GeminiAnalyzer\n",
    "    print(\"‚úì M√≥dulos del proyecto importados exitosamente\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importando m√≥dulos: {e}\")\n",
    "    print(\"Aseg√∫rese de tener instaladas las dependencias requeridas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf8db3e",
   "metadata": {},
   "source": [
    "## 1. Conexi√≥n con TCIA y Exploraci√≥n de Colecciones\n",
    "\n",
    "Primero exploraremos las colecciones disponibles en TCIA y seleccionaremos las m√°s relevantes para an√°lisis de c√°ncer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar cliente TCIA\n",
    "try:\n",
    "    tcia = TCIAClient()\n",
    "    print(\"‚úì Cliente TCIA inicializado\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error inicializando cliente TCIA: {e}\")\n",
    "    tcia = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa870457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener y analizar colecciones disponibles\n",
    "if tcia:\n",
    "    collections = tcia.get_collections()\n",
    "    \n",
    "    if collections:\n",
    "        print(f\"Total de colecciones disponibles: {len(collections)}\")\n",
    "        \n",
    "        # Mostrar primeras colecciones\n",
    "        collections_df = pd.DataFrame(collections)\n",
    "        print(\"\\nPrimeras 10 colecciones:\")\n",
    "        display(collections_df.head(10))\n",
    "    else:\n",
    "        print(\"No se pudieron obtener colecciones\")\n",
    "        collections_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680795a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar colecciones espec√≠ficas de c√°ncer\n",
    "target_collections = ['CMB-LCA', 'CMB-BRCA', 'CMB-CRC', 'CMB-MEL', 'AURORA-Metastatic-Breast-Multiomics']\n",
    "\n",
    "collection_stats = []\n",
    "\n",
    "for collection in target_collections:\n",
    "    try:\n",
    "        stats = tcia.get_collection_statistics(collection)\n",
    "        if stats:\n",
    "            collection_stats.append(stats)\n",
    "            print(f\"\\nüìä Estad√≠sticas para {collection}:\")\n",
    "            print(f\"  - Pacientes: {stats['total_patients']}\")\n",
    "            print(f\"  - Estudios: {stats['total_studies']}\")\n",
    "            print(f\"  - Series: {stats['total_series']}\")\n",
    "            print(f\"  - Modalidades: {stats['modalities']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error obteniendo estad√≠sticas de {collection}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar estad√≠sticas de colecciones\n",
    "if collection_stats:\n",
    "    stats_df = pd.DataFrame(collection_stats)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Gr√°fico de pacientes por colecci√≥n\n",
    "    axes[0,0].bar(stats_df['collection'], stats_df['total_patients'])\n",
    "    axes[0,0].set_title('N√∫mero de Pacientes por Colecci√≥n')\n",
    "    axes[0,0].set_xlabel('Colecci√≥n')\n",
    "    axes[0,0].set_ylabel('N√∫mero de Pacientes')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Gr√°fico de estudios por colecci√≥n\n",
    "    axes[0,1].bar(stats_df['collection'], stats_df['total_studies'])\n",
    "    axes[0,1].set_title('N√∫mero de Estudios por Colecci√≥n')\n",
    "    axes[0,1].set_xlabel('Colecci√≥n')\n",
    "    axes[0,1].set_ylabel('N√∫mero de Estudios')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Gr√°fico de series por colecci√≥n\n",
    "    axes[1,0].bar(stats_df['collection'], stats_df['total_series'])\n",
    "    axes[1,0].set_title('N√∫mero de Series por Colecci√≥n')\n",
    "    axes[1,0].set_xlabel('Colecci√≥n')\n",
    "    axes[1,0].set_ylabel('N√∫mero de Series')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Resumen estad√≠stico\n",
    "    axes[1,1].axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "    Resumen de Colecciones:\n",
    "    \n",
    "    Total Pacientes: {stats_df['total_patients'].sum()}\n",
    "    Total Estudios: {stats_df['total_studies'].sum()}\n",
    "    Total Series: {stats_df['total_series'].sum()}\n",
    "    \n",
    "    Promedio por Colecci√≥n:\n",
    "    - Pacientes: {stats_df['total_patients'].mean():.1f}\n",
    "    - Estudios: {stats_df['total_studies'].mean():.1f}\n",
    "    - Series: {stats_df['total_series'].mean():.1f}\n",
    "    \"\"\"\n",
    "    axes[1,1].text(0.1, 0.5, summary_text, fontsize=12, va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Guardar estad√≠sticas\n",
    "    stats_df.to_csv('../results/collection_statistics.csv', index=False)\n",
    "    print(\"\\nüíæ Estad√≠sticas guardadas en results/collection_statistics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2655fa91",
   "metadata": {},
   "source": [
    "## 2. Descarga y Procesamiento de Muestra de Datos\n",
    "\n",
    "Descargaremos una muestra peque√±a de datos para an√°lisis exploratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b0d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar procesador DICOM\n",
    "try:\n",
    "    dicom_processor = DICOMProcessor()\n",
    "    print(\"‚úì Procesador DICOM inicializado\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error inicializando procesador DICOM: {e}\")\n",
    "    dicom_processor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar muestra peque√±a de la colecci√≥n de c√°ncer de pulm√≥n\n",
    "sample_collection = 'CMB-LCA'  # Lung Cancer\n",
    "\n",
    "print(f\"Descargando muestra de {sample_collection}...\")\n",
    "print(\"‚ö†Ô∏è  Esto puede tomar algunos minutos...\")\n",
    "\n",
    "try:\n",
    "    downloaded_files = tcia.download_collection_sample(\n",
    "        collection=sample_collection,\n",
    "        max_patients=2,  # Solo 2 pacientes para demo\n",
    "        max_series_per_patient=1  # 1 serie por paciente\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úì Descargados {len(downloaded_files)} archivos:\")\n",
    "    for file in downloaded_files:\n",
    "        print(f\"  - {file}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error en descarga: {e}\")\n",
    "    downloaded_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5eff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar archivos DICOM descargados\n",
    "if downloaded_files and dicom_processor:\n",
    "    processing_results = []\n",
    "    \n",
    "    for i, zip_file in enumerate(downloaded_files[:2]):  # Procesar solo los primeros 2\n",
    "        print(f\"\\nProcesando archivo {i+1}: {zip_file}\")\n",
    "        \n",
    "        output_dir = f\"../data/processed/sample_{i+1}\"\n",
    "        \n",
    "        try:\n",
    "            result = dicom_processor.process_dicom_series(zip_file, output_dir)\n",
    "            processing_results.append(result)\n",
    "            \n",
    "            print(f\"  ‚úì Procesadas {len(result['processed_images'])} im√°genes\")\n",
    "            if result['errors']:\n",
    "                print(f\"  ‚ö†Ô∏è  {len(result['errors'])} errores encontrados\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error procesando {zip_file}: {e}\")\n",
    "    \n",
    "    print(f\"\\nüìä Resumen del procesamiento:\")\n",
    "    total_images = sum(len(r['processed_images']) for r in processing_results)\n",
    "    total_errors = sum(len(r['errors']) for r in processing_results)\n",
    "    print(f\"  - Total im√°genes procesadas: {total_images}\")\n",
    "    print(f\"  - Total errores: {total_errors}\")\n",
    "else:\n",
    "    processing_results = []\n",
    "    print(\"No hay archivos para procesar o procesador no disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cbc51d",
   "metadata": {},
   "source": [
    "## 3. An√°lisis de Metadatos DICOM\n",
    "\n",
    "Analizaremos los metadatos extra√≠dos de las im√°genes DICOM para entender mejor los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95862d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidar metadatos de todas las im√°genes procesadas\n",
    "all_metadata = []\n",
    "\n",
    "for result in processing_results:\n",
    "    all_metadata.extend(result['metadata'])\n",
    "\n",
    "if all_metadata:\n",
    "    metadata_df = pd.DataFrame(all_metadata)\n",
    "    \n",
    "    print(f\"üìã Metadatos de {len(metadata_df)} im√°genes:\")\n",
    "    print(f\"Columnas disponibles: {list(metadata_df.columns)}\")\n",
    "    \n",
    "    # Mostrar muestra de metadatos\n",
    "    display(metadata_df.head())\n",
    "    \n",
    "    # An√°lisis de modalidades\n",
    "    if 'Modality' in metadata_df.columns:\n",
    "        modality_counts = metadata_df['Modality'].value_counts()\n",
    "        print(f\"\\nüî¨ Modalidades encontradas:\")\n",
    "        for modality, count in modality_counts.items():\n",
    "            print(f\"  - {modality}: {count} im√°genes\")\n",
    "    \n",
    "    # An√°lisis de dimensiones de imagen\n",
    "    if 'Rows' in metadata_df.columns and 'Columns' in metadata_df.columns:\n",
    "        print(f\"\\nüìê Dimensiones de im√°genes:\")\n",
    "        print(f\"  - Filas: {metadata_df['Rows'].describe()}\")\n",
    "        print(f\"  - Columnas: {metadata_df['Columns'].describe()}\")\n",
    "        \n",
    "        # Visualizar distribuci√≥n de tama√±os\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        metadata_df['Rows'].hist(bins=20, ax=axes[0])\n",
    "        axes[0].set_title('Distribuci√≥n de Filas')\n",
    "        axes[0].set_xlabel('N√∫mero de Filas')\n",
    "        \n",
    "        metadata_df['Columns'].hist(bins=20, ax=axes[1])\n",
    "        axes[1].set_title('Distribuci√≥n de Columnas')\n",
    "        axes[1].set_xlabel('N√∫mero de Columnas')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Guardar metadatos\n",
    "    metadata_df.to_csv('../results/dicom_metadata.csv', index=False)\n",
    "    print(\"\\nüíæ Metadatos guardados en results/dicom_metadata.csv\")\n",
    "    \n",
    "else:\n",
    "    print(\"No hay metadatos para analizar\")\n",
    "    metadata_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811053c8",
   "metadata": {},
   "source": [
    "## 4. Visualizaci√≥n de Im√°genes Procesadas\n",
    "\n",
    "Visualizaremos algunas de las im√°genes procesadas para verificar la calidad del preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar im√°genes procesadas\n",
    "processed_images = []\n",
    "\n",
    "for result in processing_results:\n",
    "    processed_images.extend(result['processed_images'])\n",
    "\n",
    "print(f\"üñºÔ∏è  Im√°genes procesadas encontradas: {len(processed_images)}\")\n",
    "\n",
    "if processed_images:\n",
    "    # Mostrar algunas im√°genes\n",
    "    n_display = min(6, len(processed_images))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(n_display):\n",
    "        try:\n",
    "            img_path = processed_images[i]\n",
    "            img = plt.imread(img_path)\n",
    "            \n",
    "            axes[i].imshow(img, cmap='gray')\n",
    "            axes[i].set_title(f'Imagen {i+1}\\n{Path(img_path).name}')\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "            # Mostrar estad√≠sticas b√°sicas\n",
    "            axes[i].text(0.02, 0.98, f'Shape: {img.shape}\\nMin: {img.min():.2f}\\nMax: {img.max():.2f}', \n",
    "                        transform=axes[i].transAxes, va='top', ha='left',\n",
    "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "            \n",
    "        except Exception as e:\n",
    "            axes[i].text(0.5, 0.5, f'Error cargando\\nimagen {i+1}\\n{e}', \n",
    "                        ha='center', va='center', transform=axes[i].transAxes)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    # Ocultar axes vac√≠os\n",
    "    for i in range(n_display, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Muestra de Im√°genes Procesadas', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No hay im√°genes procesadas para mostrar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024575f0",
   "metadata": {},
   "source": [
    "## 5. An√°lisis con Gemini AI (Opcional)\n",
    "\n",
    "Si la API de Gemini est√° configurada, realizaremos an√°lisis de algunas im√°genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar analizador Gemini (opcional)\n",
    "try:\n",
    "    gemini_analyzer = GeminiAnalyzer()\n",
    "    print(\"‚úì Analizador Gemini inicializado\")\n",
    "    gemini_available = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Analizador Gemini no disponible: {e}\")\n",
    "    print(\"   Verifique que tenga configurada la API key de Gemini\")\n",
    "    gemini_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis con Gemini de algunas im√°genes\n",
    "if gemini_available and processed_images:\n",
    "    print(\"ü§ñ Analizando im√°genes con Gemini AI...\")\n",
    "    \n",
    "    # Analizar las primeras 2 im√°genes\n",
    "    gemini_results = []\n",
    "    \n",
    "    for i, img_path in enumerate(processed_images[:2]):\n",
    "        print(f\"\\nAnalizando imagen {i+1}: {Path(img_path).name}\")\n",
    "        \n",
    "        try:\n",
    "            result = gemini_analyzer.analyze_medical_image(\n",
    "                img_path, \n",
    "                analysis_type=\"cancer_detection\"\n",
    "            )\n",
    "            gemini_results.append(result)\n",
    "            \n",
    "            print(f\"‚úì An√°lisis completado\")\n",
    "            \n",
    "            # Mostrar resumen del an√°lisis\n",
    "            if 'gemini_response' in result:\n",
    "                response = result['gemini_response'][:200] + \"...\" if len(result['gemini_response']) > 200 else result['gemini_response']\n",
    "                print(f\"  Respuesta: {response}\")\n",
    "            \n",
    "            if 'confidence_indicators' in result and result['confidence_indicators']:\n",
    "                print(f\"  Indicadores de confianza: {result['confidence_indicators']}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error analizando imagen {i+1}: {e}\")\n",
    "    \n",
    "    # Guardar resultados de Gemini\n",
    "    if gemini_results:\n",
    "        with open('../results/gemini_analysis.json', 'w') as f:\n",
    "            json.dump(gemini_results, f, indent=2)\n",
    "        print(\"\\nüíæ Resultados de Gemini guardados en results/gemini_analysis.json\")\n",
    "        \n",
    "else:\n",
    "    print(\"üîí An√°lisis con Gemini no disponible o no hay im√°genes\")\n",
    "    gemini_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551513a9",
   "metadata": {},
   "source": [
    "## 6. Resumen y Conclusiones\n",
    "\n",
    "Resumen del an√°lisis exploratorio realizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdcb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar resumen final\n",
    "print(\"üìä RESUMEN DEL AN√ÅLISIS EXPLORATORIO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüóÇÔ∏è  DATOS ANALIZADOS:\")\n",
    "print(f\"  - Colecciones TCIA exploradas: {len(target_collections)}\")\n",
    "print(f\"  - Archivos DICOM descargados: {len(downloaded_files)}\")\n",
    "print(f\"  - Im√°genes procesadas: {len(processed_images)}\")\n",
    "print(f\"  - Metadatos extra√≠dos: {len(all_metadata)}\")\n",
    "\n",
    "if collection_stats:\n",
    "    total_patients = sum(s['total_patients'] for s in collection_stats)\n",
    "    total_studies = sum(s['total_studies'] for s in collection_stats)\n",
    "    total_series = sum(s['total_series'] for s in collection_stats)\n",
    "    \n",
    "    print(f\"\\nüìà ESTAD√çSTICAS DE COLECCIONES:\")\n",
    "    print(f\"  - Total pacientes disponibles: {total_patients}\")\n",
    "    print(f\"  - Total estudios disponibles: {total_studies}\")\n",
    "    print(f\"  - Total series disponibles: {total_series}\")\n",
    "\n",
    "if not metadata_df.empty and 'Modality' in metadata_df.columns:\n",
    "    print(f\"\\nüî¨ MODALIDADES PROCESADAS:\")\n",
    "    for modality, count in metadata_df['Modality'].value_counts().items():\n",
    "        print(f\"  - {modality}: {count} im√°genes\")\n",
    "\n",
    "if gemini_results:\n",
    "    print(f\"\\nü§ñ AN√ÅLISIS CON IA:\")\n",
    "    print(f\"  - Im√°genes analizadas con Gemini: {len(gemini_results)}\")\n",
    "    print(f\"  - Resultados guardados en: results/gemini_analysis.json\")\n",
    "\n",
    "print(f\"\\nüíæ ARCHIVOS GENERADOS:\")\n",
    "output_files = [\n",
    "    'results/collection_statistics.csv',\n",
    "    'results/dicom_metadata.csv'\n",
    "]\n",
    "if gemini_results:\n",
    "    output_files.append('results/gemini_analysis.json')\n",
    "\n",
    "for file in output_files:\n",
    "    if Path(f'../{file}').exists():\n",
    "        print(f\"  ‚úì {file}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {file} (no generado)\")\n",
    "\n",
    "print(f\"\\nüéØ PR√ìXIMOS PASOS:\")\n",
    "print(f\"  1. Descargar conjuntos de datos m√°s grandes\")\n",
    "print(f\"  2. Realizar an√°lisis radi√≥mico detallado\")\n",
    "print(f\"  3. Entrenar modelos de deep learning\")\n",
    "print(f\"  4. Validar modelos con datos independientes\")\n",
    "print(f\"  5. Desarrollar pipeline de producci√≥n\")\n",
    "\n",
    "print(f\"\\n‚úÖ An√°lisis exploratorio completado: {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
