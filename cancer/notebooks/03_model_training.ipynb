{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2c22bd",
   "metadata": {},
   "source": [
    "# Entrenamiento de Modelos de Deep Learning para Detecci√≥n de C√°ncer\n",
    "\n",
    "Este notebook implementa el entrenamiento de modelos de deep learning para detecci√≥n temprana de c√°ncer, incluyendo:\n",
    "\n",
    "- CNN tradicionales (ResNet, EfficientNet)\n",
    "- Vision Transformers (ViT)\n",
    "- Modelos h√≠bridos\n",
    "- Evaluaci√≥n y comparaci√≥n de modelos\n",
    "- An√°lisis de interpretabilidad\n",
    "- Integraci√≥n con Gemini AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b24acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n inicial\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Agregar src al path\n",
    "src_path = Path('../src').absolute()\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "# Imports principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# ML/DL imports\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print(f\"‚úì TensorFlow version: {tf.__version__}\")\n",
    "    TF_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  TensorFlow no disponible\")\n",
    "    TF_AVAILABLE = False\n",
    "\n",
    "# Configurar GPU si est√° disponible\n",
    "if TF_AVAILABLE:\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(f\"‚úì GPU disponible: {len(gpus)} dispositivo(s)\")\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    else:\n",
    "        print(\"üîã Usando CPU para entrenamiento\")\n",
    "\n",
    "# Configurar visualizaciones\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(f\"Entrenamiento de modelos iniciado: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4ad0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar m√≥dulos del proyecto\n",
    "try:\n",
    "    from models.cancer_detection import CancerDetectionModel\n",
    "    from utils.gemini_analyzer import GeminiAnalyzer\n",
    "    from utils.dicom_processor import DICOMProcessor\n",
    "    print(\"‚úì M√≥dulos del proyecto importados\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importando m√≥dulos: {e}\")\n",
    "    print(\"Algunos an√°lisis pueden no estar disponibles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1300dbbe",
   "metadata": {},
   "source": [
    "## 1. Preparaci√≥n de Datos Sint√©ticos\n",
    "\n",
    "Para esta demostraci√≥n, generaremos un dataset sint√©tico que simule im√°genes m√©dicas procesadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar dataset sint√©tico para demostraci√≥n\n",
    "def generate_synthetic_medical_images(n_samples=1000, image_size=(224, 224, 3)):\n",
    "    \"\"\"Genera im√°genes m√©dicas sint√©ticas para entrenamiento.\"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generar im√°genes base\n",
    "    X = np.random.normal(0.5, 0.2, (n_samples,) + image_size)\n",
    "    \n",
    "    # Generar etiquetas (60% benigno, 40% maligno)\n",
    "    y = np.random.choice([0, 1], size=n_samples, p=[0.6, 0.4])\n",
    "    \n",
    "    # Agregar patrones diferenciadores sutiles\n",
    "    for i in range(n_samples):\n",
    "        if y[i] == 1:  # Maligno\n",
    "            # Agregar textura irregular\n",
    "            noise = np.random.normal(0, 0.3, image_size)\n",
    "            X[i] = np.clip(X[i] + noise * 0.2, 0, 1)\n",
    "            \n",
    "            # Agregar \"lesiones\" circulares\n",
    "            center_x, center_y = np.random.randint(50, image_size[0]-50, 2)\n",
    "            radius = np.random.randint(10, 30)\n",
    "            \n",
    "            y_coords, x_coords = np.ogrid[:image_size[0], :image_size[1]]\n",
    "            mask = (x_coords - center_x)**2 + (y_coords - center_y)**2 <= radius**2\n",
    "            \n",
    "            # Intensidad alterada en la \"lesi√≥n\"\n",
    "            intensity = np.random.uniform(0.2, 0.8)\n",
    "            X[i][mask] = intensity\n",
    "        \n",
    "        else:  # Benigno\n",
    "            # Textura m√°s uniforme\n",
    "            smooth_noise = np.random.normal(0, 0.1, image_size)\n",
    "            X[i] = np.clip(X[i] + smooth_noise * 0.1, 0, 1)\n",
    "    \n",
    "    # Asegurar rango [0, 1]\n",
    "    X = np.clip(X, 0, 1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "print(\"Generando dataset sint√©tico...\")\n",
    "X_synthetic, y_synthetic = generate_synthetic_medical_images(n_samples=1000)\n",
    "\n",
    "print(f\"‚úì Dataset generado:\")\n",
    "print(f\"  - Im√°genes: {X_synthetic.shape}\")\n",
    "print(f\"  - Etiquetas: {y_synthetic.shape}\")\n",
    "print(f\"  - Casos benignos: {np.sum(y_synthetic == 0)}\")\n",
    "print(f\"  - Casos malignos: {np.sum(y_synthetic == 1)}\")\n",
    "\n",
    "# Visualizar muestras\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "# Mostrar ejemplos benignos\n",
    "benign_indices = np.where(y_synthetic == 0)[0][:5]\n",
    "for i, idx in enumerate(benign_indices):\n",
    "    axes[0, i].imshow(X_synthetic[idx])\n",
    "    axes[0, i].set_title(f'Benigno {idx}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Mostrar ejemplos malignos\n",
    "malignant_indices = np.where(y_synthetic == 1)[0][:5]\n",
    "for i, idx in enumerate(malignant_indices):\n",
    "    axes[1, i].imshow(X_synthetic[idx])\n",
    "    axes[1, i].set_title(f'Maligno {idx}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('Muestras del Dataset Sint√©tico', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd383d72",
   "metadata": {},
   "source": [
    "## 2. Divisi√≥n del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dataset en entrenamiento, validaci√≥n y prueba\n",
    "if TF_AVAILABLE:\n",
    "    # Divisi√≥n inicial: 80% train+val, 20% test\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X_synthetic, y_synthetic, test_size=0.2, random_state=42, stratify=y_synthetic\n",
    "    )\n",
    "    \n",
    "    # Divisi√≥n: 80% train, 20% val del conjunto temporal\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Divisi√≥n del dataset:\")\n",
    "    print(f\"  - Entrenamiento: {X_train.shape[0]} im√°genes\")\n",
    "    print(f\"    * Benigno: {np.sum(y_train == 0)}, Maligno: {np.sum(y_train == 1)}\")\n",
    "    print(f\"  - Validaci√≥n: {X_val.shape[0]} im√°genes\")\n",
    "    print(f\"    * Benigno: {np.sum(y_val == 0)}, Maligno: {np.sum(y_val == 1)}\")\n",
    "    print(f\"  - Prueba: {X_test.shape[0]} im√°genes\")\n",
    "    print(f\"    * Benigno: {np.sum(y_test == 0)}, Maligno: {np.sum(y_test == 1)}\")\n",
    "    \n",
    "    # Convertir etiquetas a categorical para entrenamiento\n",
    "    if TF_AVAILABLE:\n",
    "        y_train_cat = keras.utils.to_categorical(y_train, 2)\n",
    "        y_val_cat = keras.utils.to_categorical(y_val, 2)\n",
    "        y_test_cat = keras.utils.to_categorical(y_test, 2)\n",
    "        \n",
    "        print(f\"\\n‚úì Etiquetas convertidas a formato categ√≥rico\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  TensorFlow no disponible - saltando divisi√≥n de datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7321a21d",
   "metadata": {},
   "source": [
    "## 3. Inicializaci√≥n del Modelo de Detecci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar modelo de detecci√≥n de c√°ncer\n",
    "if TF_AVAILABLE:\n",
    "    try:\n",
    "        cancer_model = CancerDetectionModel()\n",
    "        print(\"‚úì Modelo de detecci√≥n de c√°ncer inicializado\")\n",
    "        \n",
    "        # Mostrar configuraci√≥n\n",
    "        print(f\"\\nüìã Configuraci√≥n del modelo:\")\n",
    "        print(f\"  - Forma de entrada: {cancer_model.input_shape}\")\n",
    "        print(f\"  - N√∫mero de clases: {cancer_model.num_classes}\")\n",
    "        print(f\"  - Learning rate: {cancer_model.learning_rate}\")\n",
    "        print(f\"  - √âpocas: {cancer_model.epochs}\")\n",
    "        print(f\"  - Paciencia: {cancer_model.patience}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inicializando modelo: {e}\")\n",
    "        cancer_model = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  TensorFlow no disponible\")\n",
    "    cancer_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ca0efa",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento de Modelos CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281fcb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar diferentes arquitecturas CNN\n",
    "if cancer_model and TF_AVAILABLE:\n",
    "    \n",
    "    # Arquitecturas a probar\n",
    "    architectures = ['ResNet50', 'EfficientNetB0']\n",
    "    model_results = {}\n",
    "    \n",
    "    for arch in architectures:\n",
    "        print(f\"\\nüöÄ Entrenando modelo {arch}...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Crear una nueva instancia del modelo para cada arquitectura\n",
    "            model_instance = CancerDetectionModel()\n",
    "            \n",
    "            # Entrenar modelo (con √©pocas reducidas para demo)\n",
    "            model_instance.epochs = 5  # Reducido para demo\n",
    "            model_instance.patience = 3\n",
    "            \n",
    "            results = model_instance.train_model(\n",
    "                (X_train, y_train_cat),\n",
    "                (X_val, y_val_cat),\n",
    "                model_type=arch\n",
    "            )\n",
    "            \n",
    "            if results and 'validation_metrics' in results:\n",
    "                model_results[arch] = results\n",
    "                val_metrics = results['validation_metrics']\n",
    "                \n",
    "                print(f\"\\n‚úÖ {arch} - M√©tricas de validaci√≥n:\")\n",
    "                for metric, value in val_metrics.items():\n",
    "                    print(f\"  - {metric}: {value:.4f}\")\n",
    "                \n",
    "                # Guardar modelo\n",
    "                model_path = f\"../results/models/{arch.lower()}_model.h5\"\n",
    "                os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "                \n",
    "                if model_instance.save_model(model_path):\n",
    "                    print(f\"üíæ Modelo guardado: {model_path}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Error entrenando {arch}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error con {arch}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nüìä RESUMEN DE ENTRENAMIENTO CNN\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    if model_results:\n",
    "        comparison_df = pd.DataFrame({\n",
    "            arch: results['validation_metrics'] \n",
    "            for arch, results in model_results.items()\n",
    "        }).T\n",
    "        \n",
    "        print(\"Comparaci√≥n de modelos CNN:\")\n",
    "        display(comparison_df.round(4))\n",
    "        \n",
    "        # Visualizar m√©tricas\n",
    "        if len(model_results) > 1:\n",
    "            comparison_df.plot(kind='bar', figsize=(12, 6))\n",
    "            plt.title('Comparaci√≥n de M√©tricas por Arquitectura CNN')\n",
    "            plt.xlabel('Arquitectura')\n",
    "            plt.ylabel('Valor de M√©trica')\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No se complet√≥ el entrenamiento de ning√∫n modelo CNN\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Modelo no disponible - saltando entrenamiento CNN\")\n",
    "    model_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06e0bf",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento de Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c116cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Vision Transformer\n",
    "if cancer_model and TF_AVAILABLE:\n",
    "    print(f\"\\nüîç Entrenando Vision Transformer...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Crear instancia para ViT\n",
    "        vit_model = CancerDetectionModel()\n",
    "        vit_model.epochs = 3  # Menos √©pocas para ViT por complejidad\n",
    "        vit_model.patience = 2\n",
    "        \n",
    "        vit_results = vit_model.train_model(\n",
    "            (X_train, y_train_cat),\n",
    "            (X_val, y_val_cat),\n",
    "            model_type=\"ViT\"\n",
    "        )\n",
    "        \n",
    "        if vit_results and 'validation_metrics' in vit_results:\n",
    "            model_results['ViT'] = vit_results\n",
    "            val_metrics = vit_results['validation_metrics']\n",
    "            \n",
    "            print(f\"\\n‚úÖ Vision Transformer - M√©tricas de validaci√≥n:\")\n",
    "            for metric, value in val_metrics.items():\n",
    "                print(f\"  - {metric}: {value:.4f}\")\n",
    "            \n",
    "            # Guardar modelo ViT\n",
    "            vit_path = \"../results/models/vit_model.h5\"\n",
    "            if vit_model.save_model(vit_path):\n",
    "                print(f\"üíæ Vision Transformer guardado: {vit_path}\")\n",
    "        else:\n",
    "            print(\"‚ùå Error entrenando Vision Transformer\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error con Vision Transformer: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Saltando entrenamiento de Vision Transformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b417b1c",
   "metadata": {},
   "source": [
    "## 6. Entrenamiento de Modelo H√≠brido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06efe969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo h√≠brido CNN + ViT\n",
    "if cancer_model and TF_AVAILABLE:\n",
    "    print(f\"\\nüîó Entrenando Modelo H√≠brido (CNN + ViT)...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Crear instancia para modelo h√≠brido\n",
    "        hybrid_model = CancerDetectionModel()\n",
    "        hybrid_model.epochs = 4  # √âpocas moderadas\n",
    "        hybrid_model.patience = 2\n",
    "        \n",
    "        hybrid_results = hybrid_model.train_model(\n",
    "            (X_train, y_train_cat),\n",
    "            (X_val, y_val_cat),\n",
    "            model_type=\"Hybrid\"\n",
    "        )\n",
    "        \n",
    "        if hybrid_results and 'validation_metrics' in hybrid_results:\n",
    "            model_results['Hybrid'] = hybrid_results\n",
    "            val_metrics = hybrid_results['validation_metrics']\n",
    "            \n",
    "            print(f\"\\n‚úÖ Modelo H√≠brido - M√©tricas de validaci√≥n:\")\n",
    "            for metric, value in val_metrics.items():\n",
    "                print(f\"  - {metric}: {value:.4f}\")\n",
    "            \n",
    "            # Guardar modelo h√≠brido\n",
    "            hybrid_path = \"../results/models/hybrid_model.h5\"\n",
    "            if hybrid_model.save_model(hybrid_path):\n",
    "                print(f\"üíæ Modelo H√≠brido guardado: {hybrid_path}\")\n",
    "        else:\n",
    "            print(\"‚ùå Error entrenando Modelo H√≠brido\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error con Modelo H√≠brido: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Saltando entrenamiento de Modelo H√≠brido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84accf77",
   "metadata": {},
   "source": [
    "## 7. Comparaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d23d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n completa de todos los modelos\n",
    "if model_results:\n",
    "    print(f\"\\nüèÜ COMPARACI√ìN FINAL DE MODELOS\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    # Crear DataFrame comparativo\n",
    "    comparison_data = {}\n",
    "    \n",
    "    for model_name, results in model_results.items():\n",
    "        if 'validation_metrics' in results:\n",
    "            comparison_data[model_name] = results['validation_metrics']\n",
    "    \n",
    "    if comparison_data:\n",
    "        final_comparison = pd.DataFrame(comparison_data).T\n",
    "        \n",
    "        print(\"\\nüìä M√©tricas de Validaci√≥n por Modelo:\")\n",
    "        display(final_comparison.round(4))\n",
    "        \n",
    "        # Encontrar mejor modelo por m√©trica\n",
    "        print(\"\\nü•á Mejores modelos por m√©trica:\")\n",
    "        for metric in final_comparison.columns:\n",
    "            best_model = final_comparison[metric].idxmax()\n",
    "            best_value = final_comparison.loc[best_model, metric]\n",
    "            print(f\"  - {metric}: {best_model} ({best_value:.4f})\")\n",
    "        \n",
    "        # Visualizaciones comparativas\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Gr√°fico de barras por m√©trica\n",
    "        final_comparison.plot(kind='bar', ax=axes[0,0])\n",
    "        axes[0,0].set_title('Comparaci√≥n de M√©tricas por Modelo')\n",
    "        axes[0,0].set_xlabel('Modelo')\n",
    "        axes[0,0].set_ylabel('Valor')\n",
    "        axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Radar chart de m√©tricas (si hay m√∫ltiples m√©tricas)\n",
    "        if len(final_comparison.columns) >= 3:\n",
    "            from math import pi\n",
    "            \n",
    "            categories = list(final_comparison.columns)\n",
    "            N = len(categories)\n",
    "            \n",
    "            angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "            angles += angles[:1]\n",
    "            \n",
    "            axes[0,1].set_theta_offset(pi / 2)\n",
    "            axes[0,1].set_theta_direction(-1)\n",
    "            axes[0,1] = plt.subplot(2, 2, 2, projection='polar')\n",
    "            \n",
    "            for model_name in final_comparison.index:\n",
    "                values = final_comparison.loc[model_name].values.flatten().tolist()\n",
    "                values += values[:1]\n",
    "                \n",
    "                axes[0,1].plot(angles, values, 'o-', linewidth=2, label=model_name)\n",
    "                axes[0,1].fill(angles, values, alpha=0.25)\n",
    "            \n",
    "            axes[0,1].set_xticks(angles[:-1])\n",
    "            axes[0,1].set_xticklabels(categories)\n",
    "            axes[0,1].set_ylim(0, 1)\n",
    "            axes[0,1].set_title('Perfil de Rendimiento por Modelo')\n",
    "            axes[0,1].legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "        else:\n",
    "            axes[0,1].axis('off')\n",
    "            axes[0,1].text(0.5, 0.5, 'Radar chart requiere\\n‚â•3 m√©tricas', \n",
    "                          ha='center', va='center', transform=axes[0,1].transAxes)\n",
    "        \n",
    "        # Historial de entrenamiento (si disponible)\n",
    "        if 'history' in list(model_results.values())[0]:\n",
    "            for i, (model_name, results) in enumerate(model_results.items()):\n",
    "                if 'history' in results and 'val_accuracy' in results['history']:\n",
    "                    epochs = range(1, len(results['history']['val_accuracy'])+1)\n",
    "                    axes[1,0].plot(epochs, results['history']['val_accuracy'], \n",
    "                                 label=f'{model_name} - Val Acc', marker='o')\n",
    "                    axes[1,0].plot(epochs, results['history']['accuracy'], \n",
    "                                 label=f'{model_name} - Train Acc', linestyle='--')\n",
    "            \n",
    "            axes[1,0].set_title('Evoluci√≥n de Accuracy durante Entrenamiento')\n",
    "            axes[1,0].set_xlabel('√âpoca')\n",
    "            axes[1,0].set_ylabel('Accuracy')\n",
    "            axes[1,0].legend()\n",
    "            axes[1,0].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1,0].axis('off')\n",
    "            axes[1,0].text(0.5, 0.5, 'Historial no disponible', \n",
    "                          ha='center', va='center', transform=axes[1,0].transAxes)\n",
    "        \n",
    "        # Ranking de modelos\n",
    "        axes[1,1].axis('off')\n",
    "        \n",
    "        # Calcular score promedio\n",
    "        avg_scores = final_comparison.mean(axis=1).sort_values(ascending=False)\n",
    "        \n",
    "        ranking_text = \"üèÜ RANKING FINAL:\\n\\n\"\n",
    "        for i, (model, score) in enumerate(avg_scores.items()):\n",
    "            medal = [\"ü•á\", \"ü•à\", \"ü•â\"][i] if i < 3 else f\"{i+1}.\"\n",
    "            ranking_text += f\"{medal} {model}: {score:.3f}\\n\"\n",
    "        \n",
    "        axes[1,1].text(0.1, 0.7, ranking_text, fontsize=12, \n",
    "                      va='top', transform=axes[1,1].transAxes,\n",
    "                      bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Guardar comparaci√≥n\n",
    "        final_comparison.to_csv('../results/model_comparison.csv')\n",
    "        print(f\"\\nüíæ Comparaci√≥n guardada en: results/model_comparison.csv\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No hay datos de comparaci√≥n disponibles\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No se entrenaron modelos para comparar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa368628",
   "metadata": {},
   "source": [
    "## 8. Evaluaci√≥n en Conjunto de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe687a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el mejor modelo en conjunto de prueba\n",
    "if model_results and TF_AVAILABLE:\n",
    "    print(f\"\\nüß™ EVALUACI√ìN EN CONJUNTO DE PRUEBA\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Encontrar mejor modelo por accuracy\n",
    "        best_model_name = None\n",
    "        best_accuracy = 0\n",
    "        \n",
    "        for model_name, results in model_results.items():\n",
    "            if 'validation_metrics' in results and 'accuracy' in results['validation_metrics']:\n",
    "                acc = results['validation_metrics']['accuracy']\n",
    "                if acc > best_accuracy:\n",
    "                    best_accuracy = acc\n",
    "                    best_model_name = model_name\n",
    "        \n",
    "        if best_model_name:\n",
    "            print(f\"üèÜ Mejor modelo: {best_model_name} (Val Acc: {best_accuracy:.4f})\")\n",
    "            \n",
    "            # Cargar mejor modelo para evaluaci√≥n\n",
    "            model_path = f\"../results/models/{best_model_name.lower()}_model.h5\"\n",
    "            \n",
    "            if os.path.exists(model_path):\n",
    "                try:\n",
    "                    best_model = keras.models.load_model(model_path)\n",
    "                    print(f\"‚úì Modelo cargado desde: {model_path}\")\n",
    "                    \n",
    "                    # Evaluar en conjunto de prueba\n",
    "                    test_loss, test_acc = best_model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "                    \n",
    "                    # Predicciones\n",
    "                    y_pred_proba = best_model.predict(X_test, verbose=0)\n",
    "                    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "                    \n",
    "                    print(f\"\\nüìä Resultados en conjunto de prueba:\")\n",
    "                    print(f\"  - P√©rdida: {test_loss:.4f}\")\n",
    "                    print(f\"  - Accuracy: {test_acc:.4f}\")\n",
    "                    \n",
    "                    # Matriz de confusi√≥n\n",
    "                    cm = confusion_matrix(y_test, y_pred)\n",
    "                    \n",
    "                    # Reporte de clasificaci√≥n\n",
    "                    print(f\"\\nüìã Reporte de clasificaci√≥n:\")\n",
    "                    print(classification_report(y_test, y_pred, \n",
    "                                               target_names=['Benigno', 'Maligno']))\n",
    "                    \n",
    "                    # Visualizar matriz de confusi√≥n\n",
    "                    plt.figure(figsize=(10, 4))\n",
    "                    \n",
    "                    plt.subplot(1, 2, 1)\n",
    "                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                               xticklabels=['Benigno', 'Maligno'],\n",
    "                               yticklabels=['Benigno', 'Maligno'])\n",
    "                    plt.title(f'Matriz de Confusi√≥n - {best_model_name}')\n",
    "                    plt.xlabel('Predicci√≥n')\n",
    "                    plt.ylabel('Real')\n",
    "                    \n",
    "                    # Distribuci√≥n de probabilidades\n",
    "                    plt.subplot(1, 2, 2)\n",
    "                    \n",
    "                    # Probabilidades para cada clase\n",
    "                    prob_malignant = y_pred_proba[:, 1]\n",
    "                    \n",
    "                    benign_probs = prob_malignant[y_test == 0]\n",
    "                    malignant_probs = prob_malignant[y_test == 1]\n",
    "                    \n",
    "                    plt.hist(benign_probs, alpha=0.7, label='Benigno Real', \n",
    "                            bins=20, color='skyblue')\n",
    "                    plt.hist(malignant_probs, alpha=0.7, label='Maligno Real', \n",
    "                            bins=20, color='salmon')\n",
    "                    \n",
    "                    plt.axvline(x=0.5, color='red', linestyle='--', \n",
    "                               label='Umbral (0.5)')\n",
    "                    plt.xlabel('Probabilidad de Malignidad')\n",
    "                    plt.ylabel('Frecuencia')\n",
    "                    plt.title('Distribuci√≥n de Probabilidades Predichas')\n",
    "                    plt.legend()\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    \n",
    "                    # Guardar resultados de evaluaci√≥n\n",
    "                    test_results = {\n",
    "                        'best_model': best_model_name,\n",
    "                        'test_loss': float(test_loss),\n",
    "                        'test_accuracy': float(test_acc),\n",
    "                        'confusion_matrix': cm.tolist(),\n",
    "                        'classification_report': classification_report(\n",
    "                            y_test, y_pred, target_names=['Benigno', 'Maligno'],\n",
    "                            output_dict=True\n",
    "                        )\n",
    "                    }\n",
    "                    \n",
    "                    with open('../results/test_evaluation.json', 'w') as f:\n",
    "                        json.dump(test_results, f, indent=2)\n",
    "                    \n",
    "                    print(f\"\\nüíæ Evaluaci√≥n guardada en: results/test_evaluation.json\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error cargando/evaluando modelo: {e}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Modelo no encontrado: {model_path}\")\n",
    "        else:\n",
    "            print(\"‚ùå No se pudo identificar el mejor modelo\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en evaluaci√≥n: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No hay modelos para evaluar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8404e7b4",
   "metadata": {},
   "source": [
    "## 9. An√°lisis con Gemini AI (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04048503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de algunas im√°genes de prueba con Gemini AI\n",
    "try:\n",
    "    gemini_analyzer = GeminiAnalyzer()\n",
    "    print(\"‚úì Analizador Gemini disponible\")\n",
    "    gemini_available = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Analizador Gemini no disponible: {e}\")\n",
    "    gemini_available = False\n",
    "\n",
    "if gemini_available:\n",
    "    print(f\"\\nü§ñ AN√ÅLISIS CON GEMINI AI\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Seleccionar algunas im√°genes de prueba\n",
    "        n_analyze = min(3, len(X_test))\n",
    "        selected_indices = np.random.choice(len(X_test), n_analyze, replace=False)\n",
    "        \n",
    "        gemini_analyses = []\n",
    "        \n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            print(f\"\\nAnalizando imagen de prueba {i+1}/{n_analyze}...\")\n",
    "            \n",
    "            # Guardar imagen temporalmente\n",
    "            temp_img_path = f\"../results/temp_image_{i}.png\"\n",
    "            \n",
    "            # Convertir y guardar imagen\n",
    "            img_to_save = (X_test[idx] * 255).astype(np.uint8)\n",
    "            \n",
    "            from PIL import Image\n",
    "            pil_img = Image.fromarray(img_to_save)\n",
    "            pil_img.save(temp_img_path)\n",
    "            \n",
    "            # Analizar con Gemini\n",
    "            try:\n",
    "                analysis = gemini_analyzer.analyze_medical_image(\n",
    "                    temp_img_path, \n",
    "                    analysis_type=\"cancer_detection\"\n",
    "                )\n",
    "                \n",
    "                if analysis and 'gemini_response' in analysis:\n",
    "                    # Agregar informaci√≥n adicional\n",
    "                    analysis['true_label'] = 'Maligno' if y_test[idx] == 1 else 'Benigno'\n",
    "                    analysis['image_index'] = int(idx)\n",
    "                    \n",
    "                    if 'y_pred' in locals():\n",
    "                        analysis['model_prediction'] = 'Maligno' if y_pred[idx] == 1 else 'Benigno'\n",
    "                        analysis['prediction_confidence'] = float(y_pred_proba[idx].max())\n",
    "                    \n",
    "                    gemini_analyses.append(analysis)\n",
    "                    \n",
    "                    print(f\"‚úì An√°lisis Gemini completado\")\n",
    "                    print(f\"  - Etiqueta real: {analysis['true_label']}\")\n",
    "                    if 'model_prediction' in analysis:\n",
    "                        print(f\"  - Predicci√≥n modelo: {analysis['model_prediction']}\")\n",
    "                        print(f\"  - Confianza: {analysis['prediction_confidence']:.3f}\")\n",
    "                    \n",
    "                    # Mostrar fragmento del an√°lisis\n",
    "                    response_snippet = analysis['gemini_response'][:300] + \"...\"\n",
    "                    print(f\"  - An√°lisis Gemini: {response_snippet}\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Error en an√°lisis Gemini\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error analizando con Gemini: {e}\")\n",
    "            \n",
    "            # Limpiar archivo temporal\n",
    "            try:\n",
    "                os.remove(temp_img_path)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Guardar an√°lisis de Gemini\n",
    "        if gemini_analyses:\n",
    "            with open('../results/gemini_model_analysis.json', 'w') as f:\n",
    "                json.dump(gemini_analyses, f, indent=2)\n",
    "            \n",
    "            print(f\"\\nüíæ An√°lisis Gemini guardado en: results/gemini_model_analysis.json\")\n",
    "            print(f\"\\nüîç Gemini analiz√≥ {len(gemini_analyses)} im√°genes de prueba\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en an√°lisis con Gemini: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"üîí An√°lisis con Gemini no disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca44b2d",
   "metadata": {},
   "source": [
    "## 10. Resumen Final y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc22839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar resumen final del entrenamiento\n",
    "print(f\"\\nüéØ RESUMEN FINAL DEL ENTRENAMIENTO\")\n",
    "print(f\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä DATASET UTILIZADO:\")\n",
    "print(f\"  - Total de im√°genes: {len(X_synthetic)}\")\n",
    "print(f\"  - Resoluci√≥n: {X_synthetic.shape[1:]}\")\n",
    "print(f\"  - Casos benignos: {np.sum(y_synthetic == 0)} ({np.mean(y_synthetic == 0)*100:.1f}%)\")\n",
    "print(f\"  - Casos malignos: {np.sum(y_synthetic == 1)} ({np.mean(y_synthetic == 1)*100:.1f}%)\")\n",
    "\n",
    "if TF_AVAILABLE:\n",
    "    print(f\"\\nüöÄ MODELOS ENTRENADOS:\")\n",
    "    if model_results:\n",
    "        for i, (model_name, results) in enumerate(model_results.items(), 1):\n",
    "            print(f\"  {i}. {model_name}\")\n",
    "            if 'validation_metrics' in results and 'accuracy' in results['validation_metrics']:\n",
    "                acc = results['validation_metrics']['accuracy']\n",
    "                print(f\"     - Accuracy de validaci√≥n: {acc:.4f}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå No se complet√≥ el entrenamiento de ning√∫n modelo\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  TensorFlow no disponible - no se entrenaron modelos\")\n",
    "\n",
    "if 'best_model_name' in locals() and best_model_name:\n",
    "    print(f\"\\nüèÜ MEJOR MODELO:\")\n",
    "    print(f\"  - Arquitectura: {best_model_name}\")\n",
    "    print(f\"  - Accuracy de validaci√≥n: {best_accuracy:.4f}\")\n",
    "    if 'test_acc' in locals():\n",
    "        print(f\"  - Accuracy de prueba: {test_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nüíæ ARCHIVOS GENERADOS:\")\n",
    "output_files = [\n",
    "    'results/models/',\n",
    "    'results/model_comparison.csv',\n",
    "    'results/test_evaluation.json'\n",
    "]\n",
    "\n",
    "if 'gemini_analyses' in locals() and gemini_analyses:\n",
    "    output_files.append('results/gemini_model_analysis.json')\n",
    "\n",
    "for file_path in output_files:\n",
    "    full_path = Path(f'../{file_path}')\n",
    "    if full_path.exists():\n",
    "        if full_path.is_dir():\n",
    "            model_count = len(list(full_path.glob('*.h5')))\n",
    "            print(f\"  ‚úì {file_path} ({model_count} modelos)\")\n",
    "        else:\n",
    "            print(f\"  ‚úì {file_path}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {file_path} (no generado)\")\n",
    "\n",
    "print(f\"\\nüî¨ METODOLOG√çA EMPLEADA:\")\n",
    "print(f\"  1. Generaci√≥n de dataset sint√©tico con patrones diferenciadores\")\n",
    "print(f\"  2. Divisi√≥n estratificada train/val/test (64%/16%/20%)\")\n",
    "print(f\"  3. Entrenamiento de m√∫ltiples arquitecturas (CNN, ViT, H√≠brido)\")\n",
    "print(f\"  4. Comparaci√≥n basada en m√©tricas de validaci√≥n\")\n",
    "print(f\"  5. Evaluaci√≥n final en conjunto de prueba independiente\")\n",
    "if gemini_available:\n",
    "    print(f\"  6. An√°lisis cualitativo con Gemini AI\")\n",
    "\n",
    "print(f\"\\nüìà PR√ìXIMOS PASOS RECOMENDADOS:\")\n",
    "print(f\"  1. Entrenamiento con datos reales de TCIA\")\n",
    "print(f\"  2. Implementaci√≥n de t√©cnicas de interpretabilidad (Grad-CAM, LIME)\")\n",
    "print(f\"  3. Validaci√≥n externa con datasets independientes\")\n",
    "print(f\"  4. Optimizaci√≥n de hiperpar√°metros\")\n",
    "print(f\"  5. Desarrollo de pipeline de producci√≥n\")\n",
    "print(f\"  6. Integraci√≥n con an√°lisis radi√≥mico\")\n",
    "\n",
    "if model_results:\n",
    "    print(f\"\\n‚úÖ CONCLUSI√ìN:\")\n",
    "    print(f\"   Se entrenaron exitosamente {len(model_results)} modelos de deep learning\")\n",
    "    print(f\"   para detecci√≥n de c√°ncer. Los resultados muestran la viabilidad del\")\n",
    "    print(f\"   enfoque y proporcionan una base s√≥lida para el desarrollo de un\")\n",
    "    print(f\"   sistema de diagn√≥stico asistido por IA.\")\n",
    "else:\n",
    "    print(f\"\\n ‚ö†Ô∏è  NOTA:\")\n",
    "    print(f\"   Este notebook demuestra la metodolog√≠a de entrenamiento.\")\n",
    "    print(f\"   Para resultados √≥ptimos, se requiere un entorno con TensorFlow\")\n",
    "    print(f\"   y datos reales de im√°genes m√©dicas.\")\n",
    "\n",
    "print(f\"\\nüïí Entrenamiento completado: {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
